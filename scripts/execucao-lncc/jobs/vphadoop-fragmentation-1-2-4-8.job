#$ -S /bin/bash
#$ -q linux.q
#$ -cwd
#$ -j y

# where to send notifications
EMAIL=gabriel.tessarolli@gmail.com

# timeout of query execution
TIMEOUT=2d

# espera as variaveis abaixo. colocar com -v ao submeter o job com qsub
# nruns = numero de repeticoes. ex: nruns=5
# dbsize = tamanho da base. ex: dbsize=1GB
# queries = ids das queries a executar. ex: queries="3 5"
# ntasks = numero de tasks (max 8)
# dbtype = "sedna" ou "basex"

if [ "$nruns" = "" ] || [ "$dbsize" = "" ] || [ "$queries" = "" ] || [ "$ntasks" = "" ] || [ "$dbtype" = "" ]; then
    echo "one expected variable was not set. see the script for instructions."
    exit 1
fi

echo "Hi" | mail -s "VPHADOOP Fragmentation JOB ${JOB_ID} - Queries ${queries} started" $EMAIL

result="FAILURE"

export WS_VPHADOOP=${HOME}/ws-vphadoop
export PE_NODEFILE=$TMPDIR/hostfile
export VPLOG_DIR=${WS_VPHADOOP}/${JOB_ID}-resultados

nnodes="$(wc -l $PE_NODEFILE | cut -d' ' -f 1)"
nprocessors=$(( nnodes*ntasks ))
NFRAGMENTS="$(( nprocessors*1 )) $(( nprocessors*2 )) $(( nprocessors*4 )) $(( nprocessors*8 ))"

mkdir -p ${VPLOG_DIR}

# amount of memory to basex server java process
export BASEX_MEM=-Xmx10G

# SGBDX startup
${dbtype}-start-all-using-tmp.sh ${dbsize} ${WS_VPHADOOP}
if [ "$?" = "0" ]; then

    result="SUCCESS"

    mem_xmx=-Xmx128M

    # hadoop framework startup
    export HADOOP_NAMENODE_OPTS="${mem_xmx} $HADOOP_NAMENODE_OPTS"
    export HADOOP_SECONDARYNAMENODE_OPTS="${mem_xmx} $HADOOP_SECONDARYNAMENODE_OPTS"
    export HADOOP_DATANODE_OPTS="${mem_xmx} $HADOOP_DATANODE_OPTS"
    export HADOOP_JOBTRACKER_OPTS="${mem_xmx} $HADOOP_JOBTRACKER_OPTS"
    export HADOOP_TASKTRACKER_OPTS="${mem_xmx} $HADOOP_TASKTRACKER_OPTS"

    export HADOOP_CONF_DIR=${WS_VPHADOOP}/$JOB_ID
    export MAX_MAP_TASKS=${ntasks}
    myhadoop-configure.sh -c $HADOOP_CONF_DIR -s /tmp/$USER/$JOB_ID
    start-all.sh

    echo "**** JOB_SETUP *****"
    echo "Approach: VPHADOOP"
    echo "JOB ID: ${JOB_ID}"
    echo "DB SIZE: ${dbsize}"
    echo "QUERIES: ${queries}"
    echo "#RUNS: ${nruns}"
    echo "#NODES: ${nnodes}"
    echo "#PROCESSORS: ${nprocessors}"
    echo "Mem for each hadoop process: ${mem_xmx}"
    echo "Mem for BaseX: ${BASEX_MEM}"
    echo "**** JOB_SETUP *****"

    sleep 1m

    # queries execution
    for query in $queries; do
        
        for nfrag in $NFRAGMENTS; do

            num_splits=$nfrag
            num_records=1

            while [ $num_splits -ge $nprocessors ]; do

                for (( run=1; run<=${nruns}; run++ )); do
                    log_file=${VPLOG_DIR}/log_nnodes_${nnodes}_ntasks_${ntasks}_q_${query}_nfrag_${nfrag}_nsplits_${num_splits}_nrecords_${num_records}_run_${run}.txt
                    echo "|-> $(date)    Query ${query} - Nfrag ${nfrag} - NSplits ${num_splits} - NRecords ${num_records} - Run ${run} | ${log_file} <-|"

                    if [ -f $log_file ]; then
                        rm $log_file
                    fi
                    if [ -f /tmp/output.xml ]; then
    	                rm /tmp/output.xml
                    fi
                    ${dbtype}-drop-tmp-db.sh ${WS_VPHADOOP}
                    echo "------------------------------------------" 1>> $log_file
                    echo "JOB ID           : ${JOB_ID}" 1>> $log_file
                    echo "# nodes          : ${nnodes}" 1>> $log_file
                    echo "# tasks per node : ${ntasks}" 1>> $log_file
                    echo "Query            : ${query}" 1>> $log_file
                    echo "# runs           : ${nruns}" 1>> $log_file
                    echo "Run ID           : ${run}" 1>> $log_file
                    echo "DB size          : ${dbsize}" 1>> $log_file
                    echo "Num splits       : ${num_splits}" 1>> $log_file
                    echo "Num records      : ${num_records}" 1>> $log_file
                    echo "------------------------------------------" 1>> $log_file
                    query_file=${HOME}/new-queries/c${query}.xq
                    if [[ $dbsize == *"_MD" ]]; then
                        query_file=${HOME}/new-queries/c${query}_md.xq
                    fi
                    timeout $TIMEOUT hadoop jar vphadoop-1.0-SNAPSHOT.jar -conf configuration-${dbtype}.xml \
                                                 -Dvphadoop.svp.numsplits=${num_splits} \
                                                 -Dvphadoop.svp.numrecords=${num_records} \
                                                 ${query_file} \
                                                 /tmp/output.xml \
                                                 ${HOME}/xmark/catalogs/${dbsize}/catalog.xml 1>>${log_file} 2>&1
                    if [ "$?" = "124" ]; then
                        echo "Timeout in query ${query} run ${run}!"
                        echo "Timeout!!" >> $log_file
                        result="PARTIAL SUCCESS"
                        break 2
                    else 
                        echo "Size of output : $(du -b /tmp/output.xml | cut -f 1) bytes" 1>> $log_file
                    fi
                done
                
                num_splits=$(( num_splits / 2 ))
                num_records=$(( num_records * 2 ))
            
            done
        done
    done

    # hadoop framework cleanup
    stop-all.sh
    myhadoop-cleanup.sh

fi

# SGBDX cleanup
${dbtype}-stop-all-using-tmp.sh ${WS_VPHADOOP}

echo "Hi" | mail -s "VPHADOOP Fragmentation JOB ${JOB_ID} - Queries ${queries} finished with ${result}" gabriel.tessarolli@gmail.com
sleep 5s
